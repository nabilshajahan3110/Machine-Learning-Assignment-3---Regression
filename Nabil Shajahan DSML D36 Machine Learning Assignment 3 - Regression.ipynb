{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d82f85ef-7b2a-48c5-99e9-2260f8700dcd",
   "metadata": {},
   "source": [
    "## ASSIGNMENT 3 - REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d567d91-5746-4c89-a39b-9e90f2095cb9",
   "metadata": {},
   "source": [
    "### **Objective**:\n",
    "The objective of this assignment is to evaluate your understanding of regression techniques in supervised learning by applying them to a real-world dataset.\n",
    "\n",
    "### **Dataset:**\n",
    "Use the California Housing dataset available in the sklearn library. This dataset contains information about various features of houses in California and their respective median prices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b503f96-31ca-4dd7-a9d6-502950ff698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "295c5061-d917-4462-bb71-7d564f4a26fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a473298-8dd6-4a91-94c0-84816c4d6fa1",
   "metadata": {},
   "source": [
    "### **1. Loading and Preprocessing:**\n",
    "\n",
    "○\tLoad the California Housing dataset using the fetch_california_housing function from sklearn.\n",
    "\n",
    "○\tConvert the dataset into a pandas DataFrame for easier handling.\n",
    "    \n",
    "○\tHandle missing values (if any) and perform necessary feature scaling (e.g., standardization).\n",
    "\n",
    "○\tExplain the preprocessing steps you performed and justify why they are necessary for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cae1a3f4-81d7-4bad-bfcf-d23de6ef18d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dataset:\n",
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  \n",
      "0    -122.23  \n",
      "1    -122.22  \n",
      "2    -122.24  \n",
      "3    -122.25  \n",
      "4    -122.25  \n",
      "\n",
      "Initial Target Dataset:\n",
      "0    4.526\n",
      "1    3.585\n",
      "2    3.521\n",
      "3    3.413\n",
      "4    3.422\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load the California Housing dataset\n",
    "data = fetch_california_housing()\n",
    "\n",
    "# Convert the dataset into a pandas DataFrame\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "Y = pd.Series(data.target)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Initial Dataset:\")\n",
    "print(X.head())\n",
    "print(\"\\nInitial Target Dataset:\")\n",
    "print(Y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70910d51-a4b7-43a9-8d00-6863543c06ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature properties of the dataset is:\n",
      "\t\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   MedInc      20640 non-null  float64\n",
      " 1   HouseAge    20640 non-null  float64\n",
      " 2   AveRooms    20640 non-null  float64\n",
      " 3   AveBedrms   20640 non-null  float64\n",
      " 4   Population  20640 non-null  float64\n",
      " 5   AveOccup    20640 non-null  float64\n",
      " 6   Latitude    20640 non-null  float64\n",
      " 7   Longitude   20640 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 1.3 MB\n",
      "\n",
      "Feature property of Target Dataset:\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Series name: None\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "20640 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 161.4 KB\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature properties of the dataset is:\")\n",
    "print(\"\\t\")\n",
    "X.info()\n",
    "print(\"\\nFeature property of Target Dataset:\")\n",
    "Y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88ac1809-c0bc-4162-80e2-65720ab85f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Analysis of the dataset\n",
      "\t\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.870671</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>5.429000</td>\n",
       "      <td>1.096675</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>3.070655</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>-119.569704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.899822</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2.474173</td>\n",
       "      <td>0.473911</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>10.386050</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>2.003532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>-124.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.563400</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.440716</td>\n",
       "      <td>1.006079</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>2.429741</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>-121.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.534800</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.229129</td>\n",
       "      <td>1.048780</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>2.818116</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>-118.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.743250</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.052381</td>\n",
       "      <td>1.099526</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>3.282261</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>-118.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000100</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>141.909091</td>\n",
       "      <td>34.066667</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>1243.333333</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.310000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
       "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
       "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
       "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
       "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
       "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
       "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
       "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
       "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
       "\n",
       "           AveOccup      Latitude     Longitude  \n",
       "count  20640.000000  20640.000000  20640.000000  \n",
       "mean       3.070655     35.631861   -119.569704  \n",
       "std       10.386050      2.135952      2.003532  \n",
       "min        0.692308     32.540000   -124.350000  \n",
       "25%        2.429741     33.930000   -121.800000  \n",
       "50%        2.818116     34.260000   -118.490000  \n",
       "75%        3.282261     37.710000   -118.010000  \n",
       "max     1243.333333     41.950000   -114.310000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Statistical Analysis of the dataset\")\n",
    "print(\"\\t\")\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6209dac-fc54-4673-a2a7-6d0a3b187e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Analysis of Target Dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    20640.000000\n",
       "mean         2.068558\n",
       "std          1.153956\n",
       "min          0.149990\n",
       "25%          1.196000\n",
       "50%          1.797000\n",
       "75%          2.647250\n",
       "max          5.000010\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Statistical Analysis of Target Dataset:\")\n",
    "Y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b95d1387-9e41-4303-bf6a-8b9c4207566f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      "MedInc        0\n",
      "HouseAge      0\n",
      "AveRooms      0\n",
      "AveBedrms     0\n",
      "Population    0\n",
      "AveOccup      0\n",
      "Latitude      0\n",
      "Longitude     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Check for missing values\n",
    "missing_values = X.isnull().sum()\n",
    "print(\"\\nMissing Values:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37e15bff-816b-4d38-b7f3-64c64c9a41cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "missing_values = Y.isnull().sum()\n",
    "print(\"\\nMissing Values:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "518de3d6-3275-47b0-83b7-27264fd2867d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find duplicates in Initial dataset\n",
    "X.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cbe9858-b8a9-4edf-841e-871791ba5649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaled Dataset:\n",
      "[[ 2.34476576  0.98214266  0.62855945 -0.15375759 -0.9744286  -0.04959654\n",
      "   1.05254828 -1.32783522]\n",
      " [ 2.33223796 -0.60701891  0.32704136 -0.26333577  0.86143887 -0.09251223\n",
      "   1.04318455 -1.32284391]\n",
      " [ 1.7826994   1.85618152  1.15562047 -0.04901636 -0.82077735 -0.02584253\n",
      "   1.03850269 -1.33282653]\n",
      " [ 0.93296751  1.85618152  0.15696608 -0.04983292 -0.76602806 -0.0503293\n",
      "   1.03850269 -1.33781784]\n",
      " [-0.012881    1.85618152  0.3447108  -0.03290586 -0.75984669 -0.08561576\n",
      "   1.03850269 -1.33781784]\n",
      " [ 0.08744664  1.85618152 -0.26972966  0.01466934 -0.89407076 -0.08961842\n",
      "   1.03850269 -1.33781784]\n",
      " [-0.11136631  1.85618152 -0.2009177  -0.3066332  -0.29271158 -0.0907249\n",
      "   1.03382082 -1.33781784]\n",
      " [-0.39513665  1.85618152 -0.25523193 -0.07354166 -0.23707923 -0.12347647\n",
      "   1.03382082 -1.33781784]\n",
      " [-0.94235915  1.06160074 -0.45870257  0.04425393 -0.19380963 -0.1004992\n",
      "   1.03382082 -1.34280914]\n",
      " [-0.09446958  1.85618152 -0.18528316 -0.22468709  0.1108437  -0.08650142\n",
      "   1.03382082 -1.33781784]]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "\n",
    "# Display the scaled dataset\n",
    "print(\"\\nScaled Dataset:\")\n",
    "print(scaled_X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84bcb6e5-0c2a-4722-be97-96dc72d70b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set shape of X:  (16512, 8)\n",
      "Test set shape of X: (4128, 8)\n",
      "\n",
      "Training set shape of Y (16512,)\n",
      "Test set shape of Y: (4128,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(scaled_X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nTraining set shape of X: \", X_train.shape)\n",
    "print(\"Test set shape of X:\", X_test.shape)\n",
    "print(\"\\nTraining set shape of Y\", Y_train.shape)\n",
    "print(\"Test set shape of Y:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27602a44-2447-44ca-8f01-7583ccfc447b",
   "metadata": {},
   "source": [
    "### **Explanation:**\n",
    "\n",
    "○\tLoaded the California Housing dataset using the fetch_california_housing function from sklearn. Then the dataset was converted into a pandas DataFrame for further analysis.\n",
    "\n",
    "○\t'X.info()' and 'Y.info()' were executed to determine the features and structure of the dataset. 'X.describe()' and 'Y.describe()' were executed to acquire statistical analysis of the dataset. Both functions will give us a brief idea of the dataset we are working with. \n",
    "    \n",
    "○\tMissing values can impact the model's ability to learn from the data. So 'isnull()' function was used to detect any missing values. Similarly 'X.duplicated().sum()' function was executed to ascertain presence of duplicate values, which has to be removed to ensure data accuracy. No missing/duplicate values were found.\n",
    "\n",
    "○\tUsing 'StandardScaler()' function, feature scaling was performed in order to ensure feature uniformity. This will assist in creating an efficient machine learning model.\n",
    "\n",
    "○\tFinally, the dataset was split into training and testing subsets to perform machine learning model evaluation.\n",
    "\n",
    "All these preproccessing steps ensure we have a clean and accurate dataset, which is required to create a well-rated machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ab9a87-7fd0-41df-9128-e54c6a81eea7",
   "metadata": {},
   "source": [
    "### **2. Regression Algorithm Implementation:**\n",
    "\n",
    "**Implement the following regression algorithms:**\n",
    "\n",
    "○\tLinear Regression\n",
    "\n",
    "○\tDecision Tree Regressor\n",
    "\n",
    "○\tRandom Forest Regressor\n",
    "\n",
    "○\tGradient Boosting Regressor\n",
    "\n",
    "○\tSupport Vector Regressor (SVR)\n",
    "\n",
    "**For each algorithm:**\n",
    "\n",
    "○\tProvide a brief explanation of how it works.\n",
    "    \n",
    "○\tExplain why it might be suitable for this dataset.\n",
    "\n",
    "\n",
    "### **3. Model Evaluation and Comparison:**\n",
    "\n",
    "**○ Evaluate the performance of each algorithm using the following metrics:**\n",
    "    \n",
    "    ■\tMean Squared Error (MSE)\n",
    "\n",
    "    ■\tMean Absolute Error (MAE)\n",
    "\n",
    "    ■\tR-squared Score (R²)\n",
    "\n",
    "**○ Compare the results of all models and identify:**\n",
    "\n",
    "    ■\tThe best-performing algorithm with justification.\n",
    "\n",
    "    ■\tThe worst-performing algorithm with reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8448fa1b-8cd8-496b-965c-99fafaaffee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression\n",
      "Mean Squared Error: 0.5558915986952441\n",
      "Mean Absolute Error: 0.5332001304956565\n",
      "R² Score: 0.575787706032451\n",
      "\n",
      "Decision Tree Regressor\n",
      "Mean Squared Error: 0.4942716777366763\n",
      "Mean Absolute Error: 0.4537843265503876\n",
      "R² Score: 0.6228111330554302\n",
      "\n",
      "Random Forest Regressor\n",
      "Mean Squared Error: 0.25549776668540763\n",
      "Mean Absolute Error: 0.32761306601259704\n",
      "R² Score: 0.805024407701793\n",
      "\n",
      "Gradient Boosting Regressor\n",
      "Mean Squared Error: 0.29399901242474274\n",
      "Mean Absolute Error: 0.37165044848436773\n",
      "R² Score: 0.7756433164710084\n",
      "\n",
      "Support Vector Regressor\n",
      "Mean Squared Error: 0.3551984619989429\n",
      "Mean Absolute Error: 0.397763096343787\n",
      "R² Score: 0.7289407597956454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Regression Algorithms Implementation\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree Regressor\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting Regressor\": GradientBoostingRegressor(random_state=42),\n",
    "    \"Support Vector Regressor\": SVR()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name}\")\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_pred = model.predict(X_test)\n",
    "    Y_pred\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    mse = mean_squared_error(Y_test, Y_pred)\n",
    "    mae = mean_absolute_error(Y_test, Y_pred)\n",
    "    r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "    # Display results\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"Mean Absolute Error: {mae}\")\n",
    "    print(f\"R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab363b-a36f-4521-9b3c-4f6ffa89d491",
   "metadata": {},
   "source": [
    "### **Explanations:**\n",
    "\n",
    "**1. Linear Regression**\n",
    "\n",
    "**How it works:** Linear Regression models the relationship between the features (independent variables) and the target (dependent variable) by fitting a linear equation (a straight line or hyperplane) to minimize the sum of squared residuals.\n",
    "\n",
    "**Suitability:** Works well when there is a linear relationship between features and the target.\n",
    "Suitable for the California Housing dataset if housing prices (target) are influenced by independent variables in a linear manner. However, it might not capture complex interactions between features.\n",
    "\n",
    "**2. Decision Tree Regressor**\n",
    "\n",
    "**How it works:** A Decision Tree splits the data into subsets using feature thresholds. Each split reduces the error in predicting the target. The process continues until a stopping criterion is met (e.g., minimum samples per leaf).\n",
    "\n",
    "**Suitability:** Captures non-linear relationships and feature interactions.\n",
    "Effective for the California Housing dataset as housing prices often depend on non-linear factors like location, population density, and median income.\n",
    "\n",
    "**3. Random Forest Regressor**\n",
    "\n",
    "**How it works:** Random Forest combines multiple decision trees (trained on random subsets of data and features) to produce a more stable and accurate prediction. It averages the predictions from all the trees to reduce overfitting.\n",
    "\n",
    "**Suitability:** Handles non-linearity and high-dimensional data well.\n",
    "Suitable for the California Housing dataset because of its ability to manage large feature spaces and capture complex relationships between features.\n",
    "\n",
    "**4. Gradient Boosting Regressor**\n",
    "\n",
    "**How it works:** Gradient Boosting builds models sequentially, where each model corrects the errors made by the previous one. It optimizes a loss function (e.g., Mean Squared Error) using gradient descent.\n",
    "\n",
    "**Suitability:** Excels in capturing complex relationships with fine-tuned models.\n",
    "Suitable for the California Housing dataset when the goal is high accuracy, as it effectively minimizes errors from previous models.\n",
    "\n",
    "**5. Support Vector Regressor (SVR)**\n",
    "\n",
    "**How it works:** SVR finds a hyperplane (or curve) that fits the data points within a specified margin of tolerance (epsilon). Kernel functions can be used to map the data to higher dimensions for non-linear relationships.\n",
    "\n",
    "**Suitability:** Works well with small- to medium-sized datasets and handles non-linear relationships.\n",
    "Suitable for the California Housing dataset for capturing specific non-linear patterns, though it may struggle with larger datasets due to computational complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dd97a6-844b-498a-a7c2-e812e0cb0d78",
   "metadata": {},
   "source": [
    "### **Model Evaluation**\n",
    "\n",
    "**Best Performing Model: Random Forest Regressor**\n",
    "\n",
    "Mean Squared Error (MSE): 0.2555 (lowest among all models)\n",
    "\n",
    "Mean Absolute Error (MAE): 0.3276 (lowest among all models)\n",
    "\n",
    "R² Score: 0.8050 (highest among all models)\n",
    "\n",
    "**Explanation:**\n",
    "The Random Forest Regressor achieved the highest R² score, indicating the best fit to the data and the highest proportion of variance in the target variable explained by the model. Additionally, its MSE and MAE are the lowest, showing that the model's predictions are closest to the actual values on average. This combination of high accuracy and low error makes it the best-performing model.\n",
    "\n",
    "**Worst Performing Model: Linear Regression**\n",
    "\n",
    "Mean Squared Error (MSE): 0.5559 (highest among all models)\n",
    "\n",
    "Mean Absolute Error (MAE): 0.5332 (highest among all models)\n",
    "\n",
    "R² Score: 0.5758 (lowest among all models)\n",
    "\n",
    "**Explanation:**\n",
    "The Linear Regression model has the lowest R² score, meaning it explains the least variance in the target variable. Additionally, it has the highest MSE and MAE, indicating that its predictions are farthest from the actual values on average compared to the other models. This poor performance in both accuracy and error metrics makes it the worst-performing model for this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
